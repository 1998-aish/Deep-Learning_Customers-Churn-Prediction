# ğŸ“Š Customer Churn Prediction â€“ ML & Deep Learning

## ğŸ“Œ Project Overview

This project predicts customer churn using Machine Learning and Deep Learning models.

The objective is to identify customers likely to leave so that proactive retention strategies can be applied.

This project demonstrates:

- End-to-end ML pipeline
- Data preprocessing (encoding + scaling)
- Handling imbalanced data
- Model comparison
- Threshold tuning
- ROC & Precisionâ€“Recall analysis

---

## ğŸ¯ Problem Statement

Customer churn leads to revenue loss.  
The goal is to predict whether a customer will churn.

This is a **binary classification problem**:

- `1` â†’ Churn  
- `0` â†’ No Churn  

Since churn represents ~26% of customers, recall is prioritized over raw accuracy.

---

## ğŸ—‚ Dataset

- Telco Customer Churn Dataset
- ~7,000 customers
- 20 features including:
  - Demographics
  - Contract details
  - Service usage
  - Monthly and total charges

---

## âš™ï¸ Data Preprocessing

- Removed `customerID`
- Converted `TotalCharges` to numeric
- Dropped missing values
- Encoded target variable (`Churn`) as 0/1
- Stratified train-test split
- One-Hot Encoding for categorical variables
- Standard Scaling for numerical features

To prevent data leakage:
- Encoders and scalers were fitted only on training data.

---

## ğŸ¤– Models Implemented

### 1ï¸âƒ£ Logistic Regression (Baseline)

- Strong tabular baseline
- Interpretable and efficient
- ~80% accuracy
- Recall (Churn) â‰ˆ 0.57

---

### 2ï¸âƒ£ Neural Network (Deep Learning)

Architecture:

- Dense (ReLU)
- Dropout
- Dense (ReLU)
- Dropout
- Output (Sigmoid)

Training Setup:

- Loss: Binary Crossentropy
- Optimizer: Adam
- Early stopping
- Batch size = 32

Results:

- Accuracy â‰ˆ 80%
- Lowering threshold improved recall to ~0.78
- Trade-off between precision and recall observed

---

## ğŸ“Š Evaluation Metrics

- Accuracy
- Precision
- Recall
- F1-score
- Confusion Matrix
- ROC Curve
- Precisionâ€“Recall Curve

Primary Business Metric:

> Recall for churn class (to reduce missed churners)

---

## ğŸ“ˆ ROC & Precisionâ€“Recall Analysis

- ROC Curve measures class separation ability.
- AUC close to 1 indicates better performance.
- Precisionâ€“Recall Curve is more informative for imbalanced data.
- Threshold tuning improves business-focused performance.

---

## ğŸ§  Key Insights

- Logistic Regression performed competitively.
- Deep Learning did not significantly outperform baseline.
- Threshold tuning improved churn recall.
- Business metrics are more important than raw accuracy.
- Deep Learning is not always superior for structured tabular data.

---

## ğŸ›  Tech Stack

- Python
- Pandas
- NumPy
- Scikit-learn
- TensorFlow / Keras
- Matplotlib

---

## ğŸ“ Project Structure

```
churn-prediction-ml/
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ notebook/
â”œâ”€â”€ images/
â”œâ”€â”€ README.md
```

---

## ğŸ‘¨â€ğŸ’» Author

Aish  
Data Science & Machine Learning Enthusiast
